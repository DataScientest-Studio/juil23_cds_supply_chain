{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_avis</th>\n",
       "      <th>sentiment_norm</th>\n",
       "      <th>longueur_texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727087</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57109</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.989352</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83051</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.825514</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_avis  sentiment_norm  longueur_texte\n",
       "5529      1.0        0.727087              95\n",
       "57109     1.0       -0.989352              73\n",
       "83051     3.0        0.825514              85"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.metrics import make_scorer, classification_report, make_scorer, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# importing training set\n",
    "train = pd.read_csv(\"../data/avis/train_noYC_lemma_sent_equil.csv\", index_col=0)\n",
    "# split between features(X) and target(y)\n",
    "y_train = train.etoiles -1 # les classes doivent commencer à 0, remettre +1 pour interpretation!\n",
    "X_train = train.drop(\"etoiles\", axis = 1)\n",
    "X_train = X_train[['n_avis','sentiment_norm','longueur_texte']]\n",
    "\n",
    "# importing test set\n",
    "test = pd.read_csv('../data/avis/test_noYC_lemma_sent_equil.csv')\n",
    "# split between features(X) and target(y)\n",
    "X_test = test.drop(\"etoiles\", axis =1)\n",
    "X_test = X_test[['n_avis','sentiment_norm','longueur_texte']]\n",
    "y_test = test['etoiles'] -1 # les classes doivent commencer à 0, remettre +1 pour interpretation!\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de vectorisation et de reporting\n",
    "def model_report():\n",
    "    # measuring time taken to train the model\n",
    "    t1 = time.time()\n",
    "    delais = round((t1-t0)/60,2)\n",
    "    # test score\n",
    "    try:\n",
    "        score = round(model.score(X_test, y_test),2)\n",
    "    except:\n",
    "        score =  \"na\"\n",
    "    print(\"train score: \", score)\n",
    "\n",
    "    # predictiong on test set, accomodating to dm matrix in except (test contains X and y)\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "    except:\n",
    "        y_pred = model.predict(test)\n",
    "    \n",
    "    # saving results in the benchmark file\n",
    "    model_name = type(model).__name__\n",
    "    report =classification_report(y_test, y_pred, output_dict=True)\n",
    "    macro_precision =  round(report['macro avg']['precision'],2) \n",
    "    macro_recall = round(report['macro avg']['recall'],2)    \n",
    "    macro_f1 = round(report['macro avg']['f1-score'],2)  \n",
    "    tempdf = pd.DataFrame({\"model\":[type(model).__name__],\n",
    "                       \"features\": [X_train.columns.values],\n",
    "                       \"score\":[score],\n",
    "                       \"precision\": [macro_precision],\n",
    "                       \"recall\": [macro_recall],\n",
    "                       \"f1\":[macro_f1],\n",
    "                       \"time_taken_mns\":[delais],\n",
    "                       \"run_date\": [time.strftime('%Y-%m-%d', time.localtime())]\n",
    "                       })\n",
    "    # reports: classification report and crosstab heatmap \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # Generate and normalize the confusion matrix\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    # Create a heatmap for the confusion matrix\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(conf_mat_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "    plt.title(f'Normalized Confusion Matrix for {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "    # load and append results to the benchmark, save\n",
    "    bench = pd.read_csv('../reports/model_benchmark.csv', index_col=0)\n",
    "    bench = pd.concat([bench, tempdf])\n",
    "    bench.to_csv('../reports/model_benchmark.csv')\n",
    "def review_vector(df,extra_features):\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # 1000 pour garder l'essentiel, plus?\n",
    "    vec_text = tfidf_vectorizer.fit_transform(df['text_lemma'])\n",
    "    print(vec_text[0:5])\n",
    "    # Ajouter les variables en format dense, comme le texte vectorisé\n",
    "    df_tf = hstack([vec_text, csr_matrix(df[extra_features])])\n",
    "    return df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.58185\teval-mlogloss:1.58629\n",
      "[1]\ttrain-mlogloss:1.55771\teval-mlogloss:1.56647\n",
      "[2]\ttrain-mlogloss:1.53629\teval-mlogloss:1.54870\n",
      "[3]\ttrain-mlogloss:1.51729\teval-mlogloss:1.53364\n",
      "[4]\ttrain-mlogloss:1.50081\teval-mlogloss:1.52012\n",
      "[5]\ttrain-mlogloss:1.48546\teval-mlogloss:1.50839\n",
      "[6]\ttrain-mlogloss:1.47168\teval-mlogloss:1.49778\n",
      "[7]\ttrain-mlogloss:1.45955\teval-mlogloss:1.48860\n",
      "[8]\ttrain-mlogloss:1.44806\teval-mlogloss:1.48003\n",
      "[9]\ttrain-mlogloss:1.43755\teval-mlogloss:1.47283\n",
      "[10]\ttrain-mlogloss:1.42808\teval-mlogloss:1.46626\n",
      "[11]\ttrain-mlogloss:1.41963\teval-mlogloss:1.46050\n",
      "[12]\ttrain-mlogloss:1.41152\teval-mlogloss:1.45555\n",
      "[13]\ttrain-mlogloss:1.40410\teval-mlogloss:1.45121\n",
      "[14]\ttrain-mlogloss:1.39747\teval-mlogloss:1.44742\n",
      "[15]\ttrain-mlogloss:1.39063\teval-mlogloss:1.44370\n",
      "[16]\ttrain-mlogloss:1.38481\teval-mlogloss:1.44027\n",
      "[17]\ttrain-mlogloss:1.37883\teval-mlogloss:1.43713\n",
      "[18]\ttrain-mlogloss:1.37356\teval-mlogloss:1.43425\n",
      "[19]\ttrain-mlogloss:1.36869\teval-mlogloss:1.43209\n",
      "[20]\ttrain-mlogloss:1.36334\teval-mlogloss:1.42956\n",
      "[21]\ttrain-mlogloss:1.35906\teval-mlogloss:1.42779\n",
      "[22]\ttrain-mlogloss:1.35419\teval-mlogloss:1.42601\n",
      "[23]\ttrain-mlogloss:1.34977\teval-mlogloss:1.42453\n",
      "[24]\ttrain-mlogloss:1.34621\teval-mlogloss:1.42318\n",
      "[25]\ttrain-mlogloss:1.34232\teval-mlogloss:1.42216\n",
      "[26]\ttrain-mlogloss:1.33910\teval-mlogloss:1.42079\n",
      "[27]\ttrain-mlogloss:1.33593\teval-mlogloss:1.41971\n",
      "[28]\ttrain-mlogloss:1.33253\teval-mlogloss:1.41889\n",
      "[29]\ttrain-mlogloss:1.32933\teval-mlogloss:1.41829\n",
      "[30]\ttrain-mlogloss:1.32624\teval-mlogloss:1.41756\n",
      "[31]\ttrain-mlogloss:1.32353\teval-mlogloss:1.41682\n",
      "[32]\ttrain-mlogloss:1.32066\teval-mlogloss:1.41668\n",
      "[33]\ttrain-mlogloss:1.31806\teval-mlogloss:1.41611\n",
      "[34]\ttrain-mlogloss:1.31529\teval-mlogloss:1.41609\n",
      "[35]\ttrain-mlogloss:1.31281\teval-mlogloss:1.41573\n",
      "[36]\ttrain-mlogloss:1.31025\teval-mlogloss:1.41548\n",
      "[37]\ttrain-mlogloss:1.30772\teval-mlogloss:1.41495\n",
      "[38]\ttrain-mlogloss:1.30519\teval-mlogloss:1.41490\n",
      "[39]\ttrain-mlogloss:1.30272\teval-mlogloss:1.41438\n",
      "[40]\ttrain-mlogloss:1.30049\teval-mlogloss:1.41439\n",
      "[41]\ttrain-mlogloss:1.29837\teval-mlogloss:1.41441\n",
      "[42]\ttrain-mlogloss:1.29602\teval-mlogloss:1.41441\n",
      "[43]\ttrain-mlogloss:1.29385\teval-mlogloss:1.41411\n",
      "[44]\ttrain-mlogloss:1.29176\teval-mlogloss:1.41374\n",
      "[45]\ttrain-mlogloss:1.28997\teval-mlogloss:1.41361\n",
      "[46]\ttrain-mlogloss:1.28789\teval-mlogloss:1.41392\n",
      "[47]\ttrain-mlogloss:1.28587\teval-mlogloss:1.41366\n",
      "[48]\ttrain-mlogloss:1.28411\teval-mlogloss:1.41341\n",
      "[49]\ttrain-mlogloss:1.28223\teval-mlogloss:1.41364\n",
      "[50]\ttrain-mlogloss:1.28027\teval-mlogloss:1.41374\n",
      "[51]\ttrain-mlogloss:1.27874\teval-mlogloss:1.41385\n",
      "[52]\ttrain-mlogloss:1.27635\teval-mlogloss:1.41357\n",
      "[53]\ttrain-mlogloss:1.27474\teval-mlogloss:1.41370\n",
      "[54]\ttrain-mlogloss:1.27291\teval-mlogloss:1.41411\n",
      "[55]\ttrain-mlogloss:1.27157\teval-mlogloss:1.41411\n",
      "[56]\ttrain-mlogloss:1.26967\teval-mlogloss:1.41397\n",
      "[57]\ttrain-mlogloss:1.26832\teval-mlogloss:1.41375\n",
      "[58]\ttrain-mlogloss:1.26642\teval-mlogloss:1.41400\n",
      "[59]\ttrain-mlogloss:1.26539\teval-mlogloss:1.41403\n",
      "[60]\ttrain-mlogloss:1.26425\teval-mlogloss:1.41384\n",
      "[61]\ttrain-mlogloss:1.26333\teval-mlogloss:1.41385\n",
      "[62]\ttrain-mlogloss:1.26226\teval-mlogloss:1.41388\n",
      "[63]\ttrain-mlogloss:1.26111\teval-mlogloss:1.41389\n",
      "[64]\ttrain-mlogloss:1.25942\teval-mlogloss:1.41396\n",
      "[65]\ttrain-mlogloss:1.25821\teval-mlogloss:1.41409\n",
      "[66]\ttrain-mlogloss:1.25733\teval-mlogloss:1.41422\n",
      "[67]\ttrain-mlogloss:1.25619\teval-mlogloss:1.41429\n",
      "[68]\ttrain-mlogloss:1.25508\teval-mlogloss:1.41419\n",
      "[69]\ttrain-mlogloss:1.25401\teval-mlogloss:1.41445\n",
      "[70]\ttrain-mlogloss:1.25241\teval-mlogloss:1.41444\n",
      "[71]\ttrain-mlogloss:1.25068\teval-mlogloss:1.41461\n",
      "[72]\ttrain-mlogloss:1.24977\teval-mlogloss:1.41460\n",
      "[73]\ttrain-mlogloss:1.24847\teval-mlogloss:1.41494\n",
      "[74]\ttrain-mlogloss:1.24760\teval-mlogloss:1.41512\n",
      "[75]\ttrain-mlogloss:1.24618\teval-mlogloss:1.41509\n",
      "[76]\ttrain-mlogloss:1.24550\teval-mlogloss:1.41511\n",
      "[77]\ttrain-mlogloss:1.24459\teval-mlogloss:1.41502\n",
      "[78]\ttrain-mlogloss:1.24335\teval-mlogloss:1.41527\n",
      "[79]\ttrain-mlogloss:1.24237\teval-mlogloss:1.41543\n",
      "[80]\ttrain-mlogloss:1.24150\teval-mlogloss:1.41570\n",
      "[81]\ttrain-mlogloss:1.24072\teval-mlogloss:1.41578\n",
      "[82]\ttrain-mlogloss:1.23933\teval-mlogloss:1.41595\n",
      "[83]\ttrain-mlogloss:1.23785\teval-mlogloss:1.41573\n",
      "[84]\ttrain-mlogloss:1.23667\teval-mlogloss:1.41600\n",
      "[85]\ttrain-mlogloss:1.23530\teval-mlogloss:1.41642\n",
      "[86]\ttrain-mlogloss:1.23426\teval-mlogloss:1.41680\n",
      "[87]\ttrain-mlogloss:1.23348\teval-mlogloss:1.41688\n",
      "[88]\ttrain-mlogloss:1.23226\teval-mlogloss:1.41687\n",
      "[89]\ttrain-mlogloss:1.23066\teval-mlogloss:1.41692\n",
      "[90]\ttrain-mlogloss:1.22953\teval-mlogloss:1.41720\n",
      "[91]\ttrain-mlogloss:1.22891\teval-mlogloss:1.41732\n",
      "[92]\ttrain-mlogloss:1.22780\teval-mlogloss:1.41743\n",
      "[93]\ttrain-mlogloss:1.22665\teval-mlogloss:1.41749\n",
      "[94]\ttrain-mlogloss:1.22583\teval-mlogloss:1.41759\n",
      "[95]\ttrain-mlogloss:1.22459\teval-mlogloss:1.41778\n",
      "[96]\ttrain-mlogloss:1.22341\teval-mlogloss:1.41786\n",
      "[97]\ttrain-mlogloss:1.22196\teval-mlogloss:1.41807\n",
      "[98]\ttrain-mlogloss:1.22022\teval-mlogloss:1.41793\n",
      "[99]\ttrain-mlogloss:1.21939\teval-mlogloss:1.41836\n",
      "train score:  na\n",
      "col_0    0.0  1.0  2.0  3.0  4.0\n",
      "etoiles                         \n",
      "0        287  116   49   62   48\n",
      "1        184  154   92   62   70\n",
      "2        129   70  144   89  130\n",
      "3         57   27   76  170  232\n",
      "4         44   32   63  155  268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.51      0.45       562\n",
      "           1       0.39      0.27      0.32       562\n",
      "           2       0.34      0.26      0.29       562\n",
      "           3       0.32      0.30      0.31       562\n",
      "           4       0.36      0.48      0.41       562\n",
      "\n",
      "    accuracy                           0.36      2810\n",
      "   macro avg       0.36      0.36      0.36      2810\n",
      "weighted avg       0.36      0.36      0.36      2810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train =xgb.DMatrix(data= X_train,label = y_train)\n",
    "test = xgb.DMatrix(data= X_test, label = y_test)\n",
    "params = {'booster': 'gbtree', 'learning_rate': 0.1, 'objective': 'multi:softmax', 'num_class' : 5}\n",
    "t0= time.time()\n",
    "model = xgb.train(params=params, dtrain=train, num_boost_round=100, evals=[(train, 'train'), (test, 'eval')])\n",
    "y_pred = model.predict(test)\n",
    "model_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essai Grid base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8748 candidates, totalling 26244 fits\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.7;, score=0.334 total time=   0.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.7;, score=0.349 total time=   0.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.7;, score=0.347 total time=   0.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.8;, score=0.338 total time=   0.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.8;, score=0.348 total time=   0.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.8;, score=0.347 total time=   0.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.9;, score=0.333 total time=   0.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.9;, score=0.349 total time=   0.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=0, subsample=0.9;, score=0.345 total time=   0.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.332 total time=   0.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.350 total time=   0.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.348 total time=   0.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.8;, score=0.334 total time=   0.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.8;, score=0.350 total time=   0.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.8;, score=0.347 total time=   0.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.9;, score=0.334 total time=   0.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.9;, score=0.350 total time=   0.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=1, subsample=0.9;, score=0.341 total time=   0.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.7;, score=0.333 total time=   0.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.7;, score=0.344 total time=   0.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.7;, score=0.346 total time=   0.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.8;, score=0.334 total time=   0.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.8;, score=0.349 total time=   0.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.8;, score=0.346 total time=   0.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.9;, score=0.334 total time=   0.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.9;, score=0.347 total time=   0.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0, reg_lambda=10, subsample=0.9;, score=0.338 total time=   0.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.7;, score=0.332 total time=   0.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.7;, score=0.350 total time=   0.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.7;, score=0.345 total time=   0.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.8;, score=0.336 total time=   0.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.8;, score=0.348 total time=   0.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.8;, score=0.348 total time=   0.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.9;, score=0.334 total time=   0.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.9;, score=0.346 total time=   0.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=0, subsample=0.9;, score=0.347 total time=   0.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=1, subsample=0.7;, score=0.334 total time=   0.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, reg_alpha=0.1, reg_lambda=1, subsample=0.7;, score=0.353 total time=   0.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m xgb_clf \u001b[39m=\u001b[39m XGBClassifier()\n\u001b[1;32m     14\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39m xgb_clf, param_grid \u001b[39m=\u001b[39m params,\n\u001b[1;32m     15\u001b[0m                      scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, cv \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m,verbose \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Saving the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m dump, load\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1520\u001b[0m     params,\n\u001b[1;32m   1521\u001b[0m     train_dmatrix,\n\u001b[1;32m   1522\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1523\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1524\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1525\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1526\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1527\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1528\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1529\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1530\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1531\u001b[0m )\n\u001b[1;32m   1533\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[1;32m   2052\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[1;32m   2053\u001b[0m         )\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = xgb.DMatrix(data= X_train,label = y_train)\n",
    "test = xgb.DMatrix(data= X_test, label = y_test)\n",
    "\n",
    "params = {'learning_rate': [0.1, 0.01, 0.05],\n",
    "          'max_depth': [3, 4, 5, 6],\n",
    "          'min_child_weight': [1, 3, 5],\n",
    "          'gamma': [0, 0.1, 0.2],\n",
    "          'subsample': [0.7, 0.8, 0.9],\n",
    "          'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "          'reg_lambda': [0, 1, 10],\n",
    "          'reg_alpha': [0, 0.1, 1]\n",
    "}\n",
    "t0= time.time()\n",
    "xgb_clf = XGBClassifier()\n",
    "model = GridSearchCV(estimator= xgb_clf, param_grid = params,\n",
    "                     scoring = 'accuracy', cv = 3,verbose = 3)\n",
    "model.fit(X_train, y_train)\n",
    "# Saving the model\n",
    "from joblib import dump, load\n",
    "dump(model, '../data/XGBoost_grid_base.joblib')\n",
    "# pour charger le modèle:\n",
    "# grid_search = load('../data/XGBoost_grid_base.joblib')\n",
    "\n",
    "# scores:\n",
    "model_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test avec TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Vectorization des avis lémmatisés\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train \u001b[39m=\u001b[39m DST_review_vector(train)\n\u001b[1;32m      3\u001b[0m X_test \u001b[39m=\u001b[39m DST_review_vector(test)\n\u001b[1;32m      5\u001b[0m train \u001b[39m=\u001b[39mxgb\u001b[39m.\u001b[39mDMatrix(data\u001b[39m=\u001b[39m X_train,label \u001b[39m=\u001b[39m y_train)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Vectorization des avis lémmatisés\n",
    "X_train = review_vector(train, [])\n",
    "X_test = review_vector(test,[])\n",
    "\n",
    "train =xgb.DMatrix(data= X_train,label = y_train)\n",
    "test = xgb.DMatrix(data= X_test, label = y_test)\n",
    "\n",
    "params = {'learning_rate': [0.1, 0.01, 0.05],\n",
    "          'max_depth': [3, 4, 5, 6],\n",
    "          'min_child_weight': [1, 3, 5],\n",
    "          'gamma': [0, 0.1, 0.2],\n",
    "          'subsample': [0.7, 0.8, 0.9],\n",
    "          'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "          'reg_lambda': [0, 1, 10],\n",
    "          'reg_alpha': [0, 0.1, 1]}\n",
    "t0= time.time()\n",
    "xgb_clf = XGBClassifier()\n",
    "model = GridSearchCV(estimator= xgb_clf, param_grid = params, scoring = 'accuracy', cv = 3,\n",
    "                    verbose = 3)\n",
    "model.fit(X_train, y_train)\n",
    "# Saving the model\n",
    "from joblib import dump, load\n",
    "\n",
    "# After your grid search has completed\n",
    "dump(model, '../data/XGBoost_grid_tfidf.joblib')\n",
    "# pour charger le modèle:\n",
    "# model_load = load('../data/XGBoost_grid_tfidf.joblib')\n",
    "\n",
    "model_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bench \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../reports/model_benchmark.csv\u001b[39m\u001b[39m'\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bench[bench\u001b[39m.\u001b[39mmodel \u001b[39m==\u001b[39m \u001b[39mtype\u001b[39m(model)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mor\u001b[39;00m bench\u001b[39m.\u001b[39mmodel \u001b[39m==\u001b[39m \u001b[39mtype\u001b[39m(grid)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "bench = pd.read_csv('../reports/model_benchmark.csv', index_col=0)\n",
    "bench[bench.model == type(model).__name__]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
