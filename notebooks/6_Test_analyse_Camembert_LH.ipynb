{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline,AutoTokenizer, TFCamembertForSequenceClassification\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/avis/df_clean_noYC_lemma.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "# chargement du modèle\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\")\n",
    "model = TFCamembertForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n",
    "\n",
    "classifier=  pipeline(\"text-classification\", model = model, tokenizer= tokenizer)\n",
    "#tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512,'return_tensors':'pt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = classifier(df['text_total'][0])\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512  # nombre de mots max pour Camembert\n",
    "\n",
    "sentiment = pd.DataFrame()\n",
    "df['label'] =np.nan\n",
    "df['score'] = np.nan\n",
    "for i, text in tqdm(enumerate(df.text_total), total=df.shape[0]):\n",
    "    # Tronquer le texte s'il est trop long\n",
    "    text = text[:MAX_LENGTH]\n",
    "    try:\n",
    "        temp = classifier(text)\n",
    "        temp = pd.DataFrame(temp)\n",
    "        df['label'][i] = temp['label'][0]\n",
    "        df['score'][i] = temp['score'][0]\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement du texte à l'indice {i}. Erreur: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des scores pour intégrer la polarité et la confiance du modèle\n",
    "# vers -1 est très probablement négativ, vers +1 est très probablement positif\n",
    "df['label'] = df.label.replace(\"NEGATIVE\", -1)\n",
    "df['label'] = df.label.replace(\"POSITIVE\", 1)\n",
    "df['sentiment_norm'] = df[\"label\"] * df[\"score\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/avis/gen_clean_lemma_sent_noYc_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nettoyage\n",
    "df[\"text_total\"] = df[\"text_total\"].str.replace(\"[^\\w\\s]\", \" \")\n",
    "df[\"text_total\"] = df[\"text_total\"].str.replace(\"  \", \" \")\n",
    "### No maj\n",
    "df[\"text_total\"] = df[\"text_total\"].str.lower()\n",
    "### Suppression espaces inutiles\n",
    "df[\"text_total\"] = df[\"text_total\"].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "#import pandas as pd\n",
    "\n",
    "# Load model and tokenizer\n",
    "\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"camembert-base\")\n",
    "classifier = pipeline(\"text-classification\", truncation=True, padding=True, max_length=512)\n",
    "\"\"\"\n",
    "\n",
    "texts = df['text_total'].tolist()\n",
    "\n",
    "# fourchette de batches à tester\n",
    "batch_sizes = [16, 32, 35, 38,40] \n",
    "\n",
    "# nombre de paquets à envoyer par test\n",
    "num_batches_to_test = 2\n",
    "\n",
    "# Enregistrer la performance\n",
    "performance = {}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # test sur quelques paquets\n",
    "    for i in range(0, min(num_batches_to_test * batch_size, len(texts)), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        classifier(batch)\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    observations_per_second = (batch_size * num_batches_to_test) / time_taken\n",
    "\n",
    "    performance[batch_size] = observations_per_second\n",
    "    print(f\"Batch Size: {batch_size}, Observations per second: {observations_per_second}\")\n",
    "\n",
    "# trouver le batch size optimal\n",
    "optimal_batch_size = max(performance, key=performance.get)\n",
    "print(f\"Optimal Batch Size: {optimal_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement du dataset avec la taille des paquets optimale\n",
    "from tqdm.auto import tqdm\n",
    "results = []\n",
    "n_batches = len(texts)//optimal_batch_size\n",
    "for i in tqdm(range(0, n_batches), total=n_batches):\n",
    "    start_time = time.time()\n",
    "    batch = texts[i:i+optimal_batch_size]\n",
    "    predictions = classifier(batch)\n",
    "    results.extend(predictions)\n",
    "    end_time =time.time()\n",
    "    time_taken = round(end_time - start_time, 1)\n",
    "    remaining_t = round(((n_batches - i+1)*time_taken)/60,1) \n",
    "    pcent = round(((i+1)/n_batches*100),2)\n",
    "    print(f\"\"\"batch {i+1} of {n_batches} in {time_taken} secs, {pcent}% done, {remaining_t} min to completion\"\"\")\n",
    "\n",
    "# passer les dernières cellules < batch size\n",
    "reliquat = len(df)%n_batches\n",
    "batch = texts[-reliquat:]\n",
    "predictions = classifier(batch)\n",
    "results.extend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajouter les résultats à la dataframe\n",
    "df['label'] = [result['label'] for result in results]\n",
    "df['score'] = [result['score'] for result in results]\n",
    "# transformation des scores pour intégrer la polarité et la confiance du modèle\n",
    "# vers -1 est très probablement négativ, vers +1 est très probablement positif\n",
    "df['label'] = df.label.replace(\"NEGATIVE\", -1)\n",
    "df['label'] = df.label.replace(\"POSITIVE\", 1)\n",
    "df['sentiment_norm'] = df[\"label\"] * df[\"score\"]\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
