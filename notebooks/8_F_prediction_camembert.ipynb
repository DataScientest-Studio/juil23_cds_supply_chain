{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Classification des étoiles avec camembert </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hk/zlc2z4tj3xv3c8bq4srx4y8m0000gq/T/ipykernel_74683/575343440.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5529     Permet de faire des factures et des…Permet de ...\n",
       "57109    Bien accompagnéBien accompagné, sympathique, p...\n",
       "Name: text_total, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import CamembertTokenizer,TrainingArguments, CamembertForSequenceClassification,Trainer,pipeline,AutoTokenizer, TFCamembertForSequenceClassification\n",
    "import torch \n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# in house functions: \n",
    "%run 'DST_fun.ipynb' # model_report() and review_vector() \n",
    "\n",
    "# set up camembert\n",
    "os.environ[\"TQDM_NOTEBOOK\"] = \"1\"\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"../data/avis/train_noYC_lemma_sent_equil.csv\", index_col=0)\n",
    "train_df['text_total'] = train_df['text_total'].astype(\"str\")\n",
    "y_train = train_df.etoiles\n",
    "X_train = train_df.text_total\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('../data/avis/test_noYC_lemma_sent_equil.csv')\n",
    "test_df['text_total'] = test_df['text_total'].astype(\"str\")\n",
    "y_temp = test_df['etoiles']\n",
    "X_temp = test_df.text_total\n",
    "\n",
    "model_type = \"Camembert\"\n",
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split du dataset\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size= 0.5,\n",
    "random_state = 7)\n",
    "\n",
    "\n",
    "# on doit soustraire 1 à chaque étoile car classifieur commence à 0\n",
    "y_train = y_train - 1\n",
    "y_valid = y_valid - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "# transfo into list\n",
    "X_train = X_train.tolist()\n",
    "X_valid = X_valid.tolist()\n",
    "X_test= X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "t0 = time.time()\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\") # better for our task I think\n",
    "#model = TFCamembertForSequenceClassification.from_pretrained(\"tblard/tf-allocine\", num_labels = 5) # better for our task I think\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation = True, padding = True,\n",
    "                            max_length = 512)\n",
    "valid_encodings = tokenizer(X_valid, truncation = True, padding = True, \n",
    "                            max_length= 512)\n",
    "test_encodings = tokenizer(X_test, truncation = True, padding = True, \n",
    "                            max_length= 512)\n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels = 5) # pour les 5 étoiles\n",
    "classifier=  pipeline(\"text-classification\", model = model, tokenizer= tokenizer)\n",
    "#tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512,'return_tensors':'pt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_encodings, y_train.tolist())\n",
    "valid_dataset = CustomDataset(valid_encodings, y_valid.tolist())\n",
    "test_dataset = CustomDataset(test_encodings, y_valid.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 82/8016 [02:00<3:16:04,  1.48s/it]"
     ]
    }
   ],
   "source": [
    "# entrainement du modèle\n",
    "\n",
    "\n",
    "#model = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels = 5) # pour les 5 étoiles\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= '../models',\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    warmup_steps = 500,\n",
    "    weight_decay = 0.01,\n",
    "    logging_dir = \".logs\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model= model,\n",
    "    args =  training_args,\n",
    "    train_dataset = train_dataset, \n",
    "    eval_dataset = valid_dataset)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    t1 = time.time()\n",
    "    delais = round((t1-t0)/60,2)\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    bench = pd.DataFrame({\"model\":\"Camembert classification\",\n",
    "                            \"grid search\": \"no\",\n",
    "                            \"used/best params\":\"na\",\n",
    "                            \"features\": \"text total\",\n",
    "                            \"score\":\"na\",\n",
    "                            \"precision\": [precision],\n",
    "                            \"recall\": [recall],\n",
    "                            \"f1\":[f1],\n",
    "                            \"time_taken_mns\":[delais],\n",
    "                            \"run_date\": [time.strftime('%Y-%m-%d', time.localtime())]\n",
    "                        })\n",
    "    bench.to_csv('../reports/benchmark/camembert_model_benchmark.csv')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Updating the trainer initialization with compute_metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# evaluating\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model and tokenizer\n",
    "trainer.save_model(\"../models/camembert/model_dst_camembert\")\n",
    "\n",
    "# If there is a need to save the tokenizer separately \n",
    "tokenizer.save_pretrained(\"../models/camembert/tokenizer_dst_camembert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runing predictions on test set\n",
    "\n",
    "\"\"\"\n",
    "test_encodings = tokenizer(test_dataset, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# trying with batches\n",
    "y_pred = []\n",
    "batch_size = 16\n",
    "for i in range(0, test_encodings.input_ids.size(0), batch_size):\n",
    "    batch = {k: v[i:i+batch_size] for k, v in test_encodings.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    batch_predictions = logits.argmax(-1)\n",
    "    y_pred.extend(batch_predictions.tolist())\n",
    "# Camembert reporting\n",
    "model_report()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
