{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>etoiles</th>\n",
       "      <th>n_avis</th>\n",
       "      <th>date_avis</th>\n",
       "      <th>date_experience</th>\n",
       "      <th>Soci√©t√©</th>\n",
       "      <th>text_total</th>\n",
       "      <th>text_clean_sentences_neg</th>\n",
       "      <th>text_clean_sentences_pos</th>\n",
       "      <th>text_stop</th>\n",
       "      <th>text_clean_sentences_neg_stop</th>\n",
       "      <th>text_clean_sentences_pos_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80800</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-08-02 07:32:51+00:00</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>SOFINCO</td>\n",
       "      <td>Simple et rapide. na</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simple et rapide</td>\n",
       "      <td>Simple rapide .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simple rapide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45069</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-02-23 11:30:21+00:00</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>Cofidis</td>\n",
       "      <td>Rapidit√© efficacit√©. Conseiller √† l'√©coute. R√©...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rapidit√© efficacit√©. Conseiller √† l' √©coute. R...</td>\n",
       "      <td>Rapidit√© efficacit√© . Conseiller √©coute . R√©po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rapidit√© efficacit√© . Conseiller l ' √©coute . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81625</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-06-07 04:18:33+00:00</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>SOFINCO</td>\n",
       "      <td>refus de 600 euros sans raison j'ai aucun cr√©d...</td>\n",
       "      <td>refus de 600 euros sans raison j' ai aucun cr√©...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>refus 600 euros raison aucun cr√©dit 2100 euros...</td>\n",
       "      <td>refus 600 euros raison j ' aucun cr√©dit 2100 e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60859</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-06-24 17:57:58+00:00</td>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>Immoprt</td>\n",
       "      <td>\"Rapide et efficace. Conseill√®re √† l'√©coute, e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rapide et efficace. Conseill√®re √† l' √©coute ef...</td>\n",
       "      <td>\"Rapide efficace . Conseill√®re √©coute , effica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rapide efficace . Conseill√®re l ' √©coute effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80796</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-08-02 10:29:49+00:00</td>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>SOFINCO</td>\n",
       "      <td>Demande d√©pos√©e le 25 juillet‚Ä¶ tjrs‚Ä¶. Demande ...</td>\n",
       "      <td>Demande d√©pos√©e le 25 juillet. Demande d√©pos√©e...</td>\n",
       "      <td>J‚Äô ai d√©j√† fait 3 demandes de cr√©dits chez vou...</td>\n",
       "      <td>Demande d√©pos√©e 25 juillet ‚Ä¶ tjrs ‚Ä¶ . Demande ...</td>\n",
       "      <td>Demande d√©pos√©e 25 juillet . Demande d√©pos√©e 2...</td>\n",
       "      <td>J ‚Äô 3 demandes cr√©dits honores sold√©s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  etoiles  n_avis                  date_avis date_experience  \\\n",
       "0       80800        5     2.0  2023-08-02 07:32:51+00:00      2023-08-01   \n",
       "1       45069        5     2.0  2021-02-23 11:30:21+00:00      2021-02-23   \n",
       "2       81625        1     2.0  2016-06-07 04:18:33+00:00      2016-06-07   \n",
       "3       60859        5     1.0  2017-06-24 17:57:58+00:00      2017-06-24   \n",
       "4       80796        1     3.0  2023-08-02 10:29:49+00:00      2023-07-25   \n",
       "\n",
       "   Soci√©t√©                                         text_total  \\\n",
       "0  SOFINCO                               Simple et rapide. na   \n",
       "1  Cofidis  Rapidit√© efficacit√©. Conseiller √† l'√©coute. R√©...   \n",
       "2  SOFINCO  refus de 600 euros sans raison j'ai aucun cr√©d...   \n",
       "3  Immoprt  \"Rapide et efficace. Conseill√®re √† l'√©coute, e...   \n",
       "4  SOFINCO  Demande d√©pos√©e le 25 juillet‚Ä¶ tjrs‚Ä¶. Demande ...   \n",
       "\n",
       "                            text_clean_sentences_neg  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  refus de 600 euros sans raison j' ai aucun cr√©...   \n",
       "3                                                NaN   \n",
       "4  Demande d√©pos√©e le 25 juillet. Demande d√©pos√©e...   \n",
       "\n",
       "                            text_clean_sentences_pos  \\\n",
       "0                                   Simple et rapide   \n",
       "1  Rapidit√© efficacit√©. Conseiller √† l' √©coute. R...   \n",
       "2                                                NaN   \n",
       "3  Rapide et efficace. Conseill√®re √† l' √©coute ef...   \n",
       "4  J‚Äô ai d√©j√† fait 3 demandes de cr√©dits chez vou...   \n",
       "\n",
       "                                           text_stop  \\\n",
       "0                                    Simple rapide .   \n",
       "1  Rapidit√© efficacit√© . Conseiller √©coute . R√©po...   \n",
       "2  refus 600 euros raison aucun cr√©dit 2100 euros...   \n",
       "3  \"Rapide efficace . Conseill√®re √©coute , effica...   \n",
       "4  Demande d√©pos√©e 25 juillet ‚Ä¶ tjrs ‚Ä¶ . Demande ...   \n",
       "\n",
       "                       text_clean_sentences_neg_stop  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  refus 600 euros raison j ' aucun cr√©dit 2100 e...   \n",
       "3                                                NaN   \n",
       "4  Demande d√©pos√©e 25 juillet . Demande d√©pos√©e 2...   \n",
       "\n",
       "                       text_clean_sentences_pos_stop  \n",
       "0                                      Simple rapide  \n",
       "1  Rapidit√© efficacit√© . Conseiller l ' √©coute . ...  \n",
       "2                                                NaN  \n",
       "3  Rapide efficace . Conseill√®re l ' √©coute effic...  \n",
       "4              J ‚Äô 3 demandes cr√©dits honores sold√©s  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv(\"df_sim_small.csv\")\n",
    "references = pd.read_csv('references_bag.csv')\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "#stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "# load the df with references, full and stop word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cette banque tue mon entreprise suite √†‚Ä¶. cette banque tue mon entreprise suite √† un disfonctionnements de mon compte il m'annonce qu'il vont cl√¥turer mon compte sous 60 jour a compte du 08/08/2023 je ne conteste pas. je recoins un virement sur mon compte anytime j'effectue le virement sur mon nouveau compte lol il me le bloque pour document pas assez pr√©cis apr√®s 5 jours d'envoi de mail toujours aucune r√©activit√© ni de virement alors que le document demander √† √©t√© fournis le jour m√™me cette banque est nul pour les professionnel\n",
      "l'avis consid√®re que la banque Anytime a üëé une mauvaise communication  üëé est inefficace\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_bad_com</th>\n",
       "      <th>c_bad_efficacy</th>\n",
       "      <th>c_good_efficacy</th>\n",
       "      <th>c_good_com</th>\n",
       "      <th>c_good_value</th>\n",
       "      <th>c_bad_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_bad_com  c_bad_efficacy  c_good_efficacy  c_good_com  c_good_value  \\\n",
       "0       True            True            False       False         False   \n",
       "\n",
       "   c_bad_value  \n",
       "0        False  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # pour ignorer les warnings dans la comparaison de vecteurs nulls\n",
    "\n",
    "i = np.random.randint(0,199)\n",
    "\n",
    "\n",
    "def allocate_lab(sim_score, y_pred, thresh):\n",
    "    #print(\"thresh\", thresh, \"sim_score\", sim_score)\n",
    "    try:\n",
    "        if max(sim_score) > thresh:\n",
    "            y_pred.append(1)\n",
    "            #print(max(sim_score), \"over threshold\", round(thresh,2), \"y_pred = 1\")\n",
    "        else:\n",
    "            y_pred.append(0) \n",
    "            #print(max(sim_score), \"under threshold\", round(thresh,2), \"y_pred = 0\")\n",
    "    except:\n",
    "        y_pred.append(0)\n",
    "        #print(\"error, y_pred = 0\")\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# review sentence vs reference sentence\n",
    "def decision_sentiment(sentiment,label_of_interest, word_mode):\n",
    "    # determining if using stop words or full version of reference texts\n",
    "    if \"stop\" in word_mode:\n",
    "        ref_bag = label_of_interest+\"_stop\"\n",
    "    elif \"all\" in word_mode:\n",
    "        ref_bag = label_of_interest\n",
    "    else:\n",
    "        print(\"error in word_mode?\", word_mode)\n",
    "\n",
    "    # determining if using sentiment filtered review sentences or all reviews sentences\n",
    "    if sentiment == True:\n",
    "        if \"good\" in label_of_interest:\n",
    "            if \"stop\" in word_mode:\n",
    "                reviews= \"text_clean_sentences_pos_stop\"\n",
    "            else:\n",
    "                reviews =  \"text_clean_sentences_pos\"\n",
    "        elif \"bad\" in label_of_interest:\n",
    "            if \"stop\" in word_mode:\n",
    "                reviews =  \"text_clean_sentences_neg_stop\"\n",
    "            else:\n",
    "                reviews =  \"text_clean_sentences_neg\"\n",
    "        else:\n",
    "            print(\"mispelling in label_of_interest?\", label_of_interest)\n",
    "\n",
    "    elif sentiment == False:\n",
    "        # for some reason the original, uncleaned punctuation versions give much better accuracy\n",
    "        if \"stop\" in word_mode:\n",
    "            reviews = \"text_stop\"\n",
    "        else:\n",
    "            reviews = \"text_total\"\n",
    "            \n",
    "    else :\n",
    "        print(\"error: no sentiment / granularity found\")\n",
    "\n",
    "    return reviews, ref_bag\n",
    "\n",
    "def review_sentence_vs_ref_sentence(i,df,label_of_interest, thresh,word_mode, sentiment=True):\n",
    "    test_name = \"review_sentence_vs_ref_sentence\"\n",
    "    #print(\"passing\",test_name) \n",
    "    reviews,ref_bag = decision_sentiment(sentiment,label_of_interest, word_mode)\n",
    "    ref_bag = nlp(references[ref_bag].iloc[0])\n",
    "    y_pred = [] \n",
    "    sim_score = []\n",
    "    try:\n",
    "        review = nlp(df[reviews].iloc[i])\n",
    "        review_sentences = review.sents\n",
    "        for review_sentence in review_sentences: # take each review sentence\n",
    "            if len(review_sentence) > 1:\n",
    "                for sentence_exemple in ref_bag.sents:\n",
    "                    if len(sentence_exemple) > 1:\n",
    "                        temp_sim_score = round(sentence_exemple.similarity(review_sentence),2) # test similarity with whole reference bag\n",
    "                        sim_score.append(temp_sim_score)\n",
    "    except:\n",
    "        #print(\"message null\")\n",
    "        sim_score.append(0.0)\n",
    "    y_pred = allocate_lab(sim_score, y_pred, thresh) # if similarity failed, mark as 0 (empty review or not sentence aligned with label sentiment if sentiment = True)     \n",
    "    return y_pred\n",
    "\n",
    "# Comparing whole review vs whole reference bag, returns y_pred series\n",
    "def review_vs_whole_ref_bag(i,df,label_of_interest, thresh,word_mode, sentiment=True):\n",
    "    # establish the correct review granularity, review and reference pieces to integrate based on sentiment bool, stop_word (word_mode) bool and label of interest\n",
    "    reviews,ref_bag = decision_sentiment(sentiment,label_of_interest, word_mode) \n",
    "    #print(\"for label\", label_of_interest)\n",
    "    #print(\"review colname\", reviews)\n",
    "    #print(\"reference bag colname\", ref_bag)\n",
    "    ref_bag = nlp(references[ref_bag][0]) # we convert the references once to nlp before the loop\n",
    "    y_pred = []\n",
    "    sim_score = []\n",
    "    try:\n",
    "        review = nlp(df[reviews].iloc[i])\n",
    "        sim_score.append(round(ref_bag.similarity(review),2)) # compare it with the full reference bag\n",
    "        allocate_lab(sim_score, y_pred, thresh) # if similarity score is > than threshold we append 1, otherwise: 0\n",
    "    except: # if similarity test fails, we put 0 (in this case na or non text review)\n",
    "        print(\"nan or error on message:\", review)\n",
    "        y_pred.append(0)\n",
    "    return y_pred \n",
    "    \n",
    "\n",
    "# review vs whole reference bag\n",
    "sim = pd.DataFrame()\n",
    "sim['c_bad_com'] = review_sentence_vs_ref_sentence(i,df,\"c_bad_com\", 0.73,\"stopwords\", sentiment=True)\n",
    "sim['c_bad_efficacy'] = review_vs_whole_ref_bag(i,df,\"c_bad_efficacy\", 0.86, \"allwords\", sentiment=False)\n",
    "sim['c_good_efficacy'] = review_sentence_vs_ref_sentence(i,df, \"c_good_efficacy\", 0.71,\"stopwords\", sentiment=True)\n",
    "sim['c_good_com'] = review_sentence_vs_ref_sentence(i,df, \"c_good_com\", 0.68,\"stopwords\", sentiment=True)\n",
    "sim['c_good_value'] = review_sentence_vs_ref_sentence(i,df, \"c_good_value\", 0.68,\"stopwords\", sentiment=True)\n",
    "sim['c_bad_value'] = review_sentence_vs_ref_sentence(i,df, \"c_bad_value\", 0.69,\"stopwords\", sentiment=True)\n",
    "\n",
    "sim = sim.astype(\"bool\")\n",
    "\n",
    "if sim['c_bad_com'][0]:\n",
    "    if sim['c_good_com'][0]:\n",
    "        b_com = \"üòê une communication mitig√©e\"\n",
    "    else:\n",
    "        b_com =\"üëé une mauvaise communication\"\n",
    "else:\n",
    "    if sim['c_good_com'][0]:\n",
    "        b_com = \"üëç une bonne communication\"\n",
    "    else:\n",
    "        b_com= \"\"#\"üòê une communication mitig√©e\"\n",
    "\n",
    "if sim['c_bad_value'][0]:\n",
    "    if sim['c_good_value'][0]:\n",
    "        b_value = \"üòê un rendement √©conomique mitig√©\"\n",
    "    else:\n",
    "        b_value = \"üëé un mauvais rendement √©conomique\"\n",
    "else:\n",
    "    if sim['c_good_value'][0]:\n",
    "        b_value = \"üëç un bon rendement √©conomique\"\n",
    "    else:\n",
    "        b_value = \"\"#\"üòê un rendement √©conomique mitig√©\"\n",
    "\n",
    "if sim['c_bad_efficacy'][0]:\n",
    "    if sim['c_good_efficacy'][0]:\n",
    "        b_efficacy = \"üòê une efficacit√© mitig√©e\"\n",
    "    else:\n",
    "        b_efficacy =\"üëé est inefficace\"\n",
    "else:\n",
    "    if sim['c_good_efficacy'][0]:\n",
    "        b_efficacy = \"üëç est efficace\"\n",
    "    else:\n",
    "        b_efficacy =\"\"# \"üòê a une efficacit√© mitig√©e\"\n",
    "\n",
    "print(df.text_total[i])\n",
    "\n",
    "if sim['c_bad_com'][0] + sim['c_good_com'][0] + sim['c_bad_value'][0] + sim['c_good_value'][0] + sim['c_bad_efficacy'][0] + sim['c_good_efficacy'][0]:\n",
    "    print(f\"l'avis consid√®re que la banque {df.Soci√©t√©[i]} a {b_com} {b_value} {b_efficacy}\")\n",
    "else:\n",
    "    print(\"pas de sentiment particulier d√©t√©ct√©\")\n",
    "    \n",
    "b_com,b_value,b_efficacy = \"\",\"\",\"\"\n",
    "sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim['c_bad_com'][0] + sim['c_good_com'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
